{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef3a2f1e-00ae-4871-b5bd-1036d63c24b1",
   "metadata": {},
   "source": [
    "# Indexación de documentos mediante vectores de peso (TFxIDF) - Ejemplo con motor de búsqueda de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84287f67-6445-4b08-a731-5e6a9b2146db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para importar el módulo con las funciones necesarias\n",
    "import sys\n",
    "sys.path.append(r\"D:\\Repos Github\\AnaliticaTextual-Ejemplos\") # la carpeta donde está el módulo\n",
    "\n",
    "import utils # el módulo -> utils.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ed2ca12-998f-4966-93bb-2c3e0644ee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial.distance import cosine\n",
    "import es_core_news_sm  # procesador de lenguaje con segmentación de frases, tokenización, lematización, etiquetas POS y dependencias sintácticas. Carga el modelo en español de Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b9af94c-e9d4-416c-9cff-a582f9bff21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con la función CrearQuery se prentende\n",
    "    # Construir un vector TF-IDF para una consulta (query) usando el vocabulario entrenado previamente.\n",
    "    # Si tengo un vocabulario como {\"chile\":0, \"corea\":1, \"kpop\":2, \"idol\":3, \"fan\":4} y el usario escribe \"fan de kpop\" -> La función generará un vector de la query: [0, 0, 1, 0, 1] * idf\n",
    "    # bPara luego compararlo con otros documentos mediante coseno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "680900f1-924c-484a-8db7-8b3dd6403f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crearQuery(terms,idf,vocabulario):\n",
    "    query = np.zeros(len(vocabulario)) #Crea el vector de ceros del tamaño del vocabulario\n",
    "    listaTerminos = utils.Tokenizar(utils.Lematizar(terms.lower())) #lematiza y tokenizar -> creando una lista de tokens → [\"correr\", \"detrás\", \"de\", \"los\", \"idol\"]. Tb me aseguro que está todo en minúsculas\n",
    "    for t in listaTerminos:      \n",
    "       if t in vocabulario: # vocabulario viene definido en la función  CrearVSM en utils.py-> vocabulario = modelo.vocabulary_\n",
    "           indice = vocabulario[t]\n",
    "           query[indice] = 1 #indice-> Posicón ; 1 -> valor que escribo en esta posicón. En este caso 1 = \"existencia\"\n",
    "        \n",
    "    if (np.count_nonzero(query) == 0): # Si el vector está vacío (ningún término válido), no tiene sentido devolverlo\n",
    "        return None\n",
    "    \n",
    "    query = query * idf #Aplicar los pesos IDF (TF binario × IDF). idf viene de la fucnión CrearVSM en utils.py ->idf = modelo.idf         \n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4183bb52-c39d-40a3-953d-fd69c6e5add9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función es un buscador: \n",
    "    # recibe una query vectorizada\n",
    "    # la compara con cada documento del corpus\n",
    "    # calcula la similitud\n",
    "    # Devuelve la lista ordenada del más similar al menos similar\n",
    "# Es el paso final del modelo vectorial TF-IDF\n",
    "\n",
    "def RecuperarDocumentosRelevantes(query,modelo,doc_id):\n",
    "  RelDocs = []\n",
    "  for ind_doc in range(len(doc_id)): #doc_id viene de CrearCorpus en utils.py\n",
    "    filename = doc_id[ind_doc]  \n",
    "    similitud = 1 - cosine(query,modelo[ind_doc,:])\n",
    "    RelDocs.append((similitud,filename))  \n",
    "  return(sorted(RelDocs,reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e810153-4a5e-46db-98f3-f58f57dcd2c2",
   "metadata": {},
   "source": [
    "Síntesis:\n",
    "\n",
    "distancia (cosine)\t1 - distancia\tinterpretación\n",
    "\n",
    "0.0\t                      1.0\tmuy similar\n",
    "\n",
    "0.3\t                      0.7\tmedianamente\n",
    "\n",
    "1.0\t                      0.0\tnada similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e797e23-3518-4626-aac8-a3606e763aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MostrarDocumentos(Docs): # se alimenta del resultado de RecuperarDocumentosRelevantes -> Docs = lista de tuplas (similitud, nombre_archivo).\n",
    "    print(\"Lista de documentos relevantes a la query:\\n\")\n",
    "    for (sim,d) in Docs:\n",
    "        print(\"Doc: \"+d+\" (\"+str(sim)+\")\\n\") # + -> concatena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62a24cbf-a311-45c0-b35e-9c9d72c379a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r\"D:\\Repos Github\\AnaliticaTextual-Ejemplos\\CORPUS\\deportes\"\n",
    "\n",
    "nlp           = es_core_news_sm.load()\n",
    "corpus,docsID = utils.CrearCorpus(PATH)\n",
    "textos  = utils.PreProcesar(corpus)\n",
    "utils.CrearVSM(textos,\"mi_modelo\")\n",
    "\n",
    "(tfidf, idf, vocabulario) = utils.CargarModelo(\"mi_modelo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78b88d3f-c437-4658-98be-2fa2139b6733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************\n",
      "Bienvenido al buscador de documentos!\n",
      "*********************************************\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ingrese query:  jugador suizo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de documentos relevantes a la query:\n",
      "\n",
      "Doc: d9.txt (0.077986343624597)\n",
      "\n",
      "Doc: d21.txt (0.06413267447149873)\n",
      "\n",
      "Doc: d34.txt (0.04225895295397564)\n",
      "\n",
      "Doc: d23.txt (0.038842974418654475)\n",
      "\n",
      "Doc: d30.txt (0.03621130288623453)\n",
      "\n",
      "Doc: d24.txt (0.0361293257964439)\n",
      "\n",
      "Doc: d18.txt (0.033389305242030876)\n",
      "\n",
      "Doc: d33.txt (0.03268121290887327)\n",
      "\n",
      "Doc: d27.txt (0.030200074622632966)\n",
      "\n",
      "Doc: d11.txt (0.025235341157737734)\n",
      "\n",
      "Doc: d7.txt (0.02458539337536314)\n",
      "\n",
      "Doc: d10.txt (0.016574196143898212)\n",
      "\n",
      "Doc: d8.txt (0.0)\n",
      "\n",
      "Doc: d6.txt (0.0)\n",
      "\n",
      "Doc: d5.txt (0.0)\n",
      "\n",
      "Doc: d4.txt (0.0)\n",
      "\n",
      "Doc: d32.txt (0.0)\n",
      "\n",
      "Doc: d31.txt (0.0)\n",
      "\n",
      "Doc: d3.txt (0.0)\n",
      "\n",
      "Doc: d29.txt (0.0)\n",
      "\n",
      "Doc: d28.txt (0.0)\n",
      "\n",
      "Doc: d26.txt (0.0)\n",
      "\n",
      "Doc: d25.txt (0.0)\n",
      "\n",
      "Doc: d22.txt (0.0)\n",
      "\n",
      "Doc: d20.txt (0.0)\n",
      "\n",
      "Doc: d2.txt (0.0)\n",
      "\n",
      "Doc: d19.txt (0.0)\n",
      "\n",
      "Doc: d17.txt (0.0)\n",
      "\n",
      "Doc: d16.txt (0.0)\n",
      "\n",
      "Doc: d15.txt (0.0)\n",
      "\n",
      "Doc: d14.txt (0.0)\n",
      "\n",
      "Doc: d13.txt (0.0)\n",
      "\n",
      "Doc: d12.txt (0.0)\n",
      "\n",
      "Doc: d1.txt (0.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"*********************************************\")\n",
    "print(\"Bienvenido al buscador de documentos!\")\n",
    "print(\"*********************************************\")\n",
    "\n",
    "terms = input(\"Ingrese query: \")\n",
    "vector_query = crearQuery(terms,idf,vocabulario)\n",
    "\n",
    "if len(vector_query)==0:\n",
    "    print(\"ERROR en vector de consulta, no se pueden recuperar documentos!..\")\n",
    "else:\n",
    "    DocsRelevantes = RecuperarDocumentosRelevantes(vector_query,tfidf,docsID)\n",
    "    MostrarDocumentos(DocsRelevantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190b0ddd-496e-48b0-bd27-df72ad5a4e16",
   "metadata": {},
   "source": [
    "Todo lo que se está haciendo en este notebook y .utils se puede ver así:\n",
    "\n",
    "1) Preparar datos\n",
    "\n",
    "CrearCorpus(path) → devuelve:\n",
    "\n",
    "corpus = lista de textos\n",
    "\n",
    "doc_id = lista de nombres de archivo\n",
    "\n",
    "2) Crear o cargar el modelo vectorial\n",
    "\n",
    "CrearVSM(textos, nombre_modelo, ...) → crea matriz TF/TF-IDF y la guarda con joblib\n",
    "\n",
    "CargarModelo(nombre_modelo) → devuelve:\n",
    "\n",
    "modelo (matriz documento–término)\n",
    "\n",
    "idf\n",
    "\n",
    "vocabulario\n",
    "\n",
    "3) Preprocesar una query\n",
    "\n",
    "crearQuery(terms, idf, vocabulario) → devuelve un vector TF-IDF para la consulta\n",
    "\n",
    "4) Calcular similitudes y ordenar\n",
    "\n",
    "RecuperarDocumentosRelevantes(query, modelo, doc_id) → lista de (similitud, filename)\n",
    "\n",
    "Mostrar resultados\n",
    "\n",
    "MostrarDocumentos(Docs) → imprime esa lista bonita\n",
    "\n",
    "5) Resumen del flujo:\n",
    "\n",
    "textos → corpus → VSM → query → similitudes → ranking → imprimir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046a3f1b-ef12-4431-90bd-baf227843c46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (atkinson)",
   "language": "python",
   "name": "atkinson"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
